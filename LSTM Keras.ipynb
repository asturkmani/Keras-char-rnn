{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import re\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import lxml.etree\n",
    "import itertools\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import h5py\n",
    "\n",
    "\n",
    "from keras.models import Sequential, load_model, model_from_json\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, GRU\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import np_utils\n",
    "from keras.layers.wrappers import TimeDistributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "FLAGS = tf.flags\n",
    "FLAGS.data_path = \"talks.txt\"\n",
    "FLAGS.maxlen = 50\n",
    "FLAGS.batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Download Dataset\n",
    "if not os.path.isfile('ted_en-20160408.zip'):\n",
    "    urllib.request.urlretrieve(\"https://wit3.fbk.eu/get.php?path=XML_releases/xml/ted_en-20160408.zip&filename=ted_en-20160408.zip\", filename=\"ted_en-20160408.zip\")\n",
    "\n",
    "\n",
    "# Extract documents   \n",
    "with zipfile.ZipFile('ted_en-20160408.zip', 'r') as z:\n",
    "    doc = lxml.etree.parse(z.open('ted_en-20160408.xml', 'r'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# corpus = \"\"\n",
    "# totalcorpus = \"\"\n",
    "# i=0\n",
    "# chars_to_remove = ['+', ',', '-','/','<', '=', '>','@', '[', '\\\\', ']', '^', '_','\\x80', '\\x93', '\\x94', '\\xa0', '¡', '¢', '£', '²', 'º', '¿', 'à', 'á', 'â', 'ã', 'ä', 'å', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'ì', 'í', 'ï', 'ñ', 'ó', 'ô', 'ö', 'ø', 'ù', 'û', 'ü', 'ā', 'ă', 'ć', 'č', 'ē', 'ě', 'ī', 'ō', 'ť', 'ū', '˚', 'τ', 'ย', 'ร', 'อ', '่', '€', '∇', '♪', '♫', '你', '葱', '送', '–', '—', '‘', '’', '“', '”','0', '1', '2', '3', '4', '5', '6', '7', '8', '9','#', '$', '%', '&', '!', '\"', \"'\", '(', ')', '*', ':', ';','…']\n",
    "# rx = '[' + re.escape(''.join(chars_to_remove)) + ']'\n",
    "# for document in doc.findall('//content'):\n",
    "#     i +=1\n",
    "#     # get each talk\n",
    "#     corpus = document.text.lower()\n",
    "#     # remove unwanted characters\n",
    "#     corpus = re.sub(rx, '', corpus)\n",
    "#     # create total corpus\n",
    "#     totalcorpus = totalcorpus + \" S \" + corpus + \" E \"\n",
    "# print(len(totalcorpus))\n",
    "# print(i)\n",
    "# corpus = totalcorpus\n",
    "\n",
    "# with open(FLAGS.data_path, \"w\") as text_file:\n",
    "#     text_file.write(corpus) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Load text file if processed before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def readfile(data_path):\n",
    "    corpus = open(data_path, \"r\")\n",
    "    corpus = corpus.read()\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create character to index and index to character functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_dicts(corpus):\n",
    "    chars = sorted(list(set(corpus)))\n",
    "    char2ind = dict((c, i) for i, c in enumerate(chars))\n",
    "    ind2char = dict((i, c) for i, c in enumerate(chars))\n",
    "    return char2ind, ind2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Split text into overlapping sentences with step size 3.\n",
    "# print('Splitting text into sequences...')\n",
    "def split2sentences(corpus, maxlen):\n",
    "    sentencelen = maxlen+1\n",
    "    step = 5\n",
    "    sentences = []\n",
    "    for i in range(0, len(corpus) - sentencelen, step):\n",
    "        sentences.append(corpus[i: i + sentencelen])\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def vectorize(sentences, maxlen, charlen, char_indices):\n",
    "    X = np.zeros((len(sentences), maxlen, charlen), dtype=np.bool)\n",
    "    Y = np.zeros((len(sentences), maxlen, charlen), dtype=np.bool)\n",
    "    \n",
    "    # vectorize the entire set by splitting sentences into X and Y, where Y is X shifted\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        for t, char in enumerate(sentence):\n",
    "            if t==0:\n",
    "                X[i, t, char_indices[char]] = 1\n",
    "            elif t==50:\n",
    "                Y[i, t-1, char_indices[char]] = 1\n",
    "            else:\n",
    "                X[i, t, char_indices[char]] = 1\n",
    "                Y[i, t-1, char_indices[char]] = 1\n",
    "    return X,Y\n",
    "\n",
    "def unvectorize(tensor, ind2char):\n",
    "    sentences = []\n",
    "    print(tensor.shape)\n",
    "    for i, sentence in enumerate(tensor):\n",
    "        x = \"\"\n",
    "        for j, char in enumerate(sentence):\n",
    "            y = ind2char[np.argmax(char)]\n",
    "            x += y\n",
    "        sentences.append(x)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generate_data(FLAGS):\n",
    "    corpus = readfile(FLAGS.data_path)\n",
    "    char2ind, ind2char = get_dicts(corpus)\n",
    "    sentences = split2sentences(corpus, FLAGS.maxlen)\n",
    "    num_sent = len(sentences)\n",
    "    while 1:\n",
    "        for j in range(0, num_sent, batch_size):\n",
    "            batch = sentences[j:j+batch_size]\n",
    "            X, Y = vectorize(batch, FLAGS.maxlen, len(char2ind), char2ind)\n",
    "            yield (X, Y)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS.samples_per_epoch = len(split2sentences(readfile(FLAGS.data_path), FLAGS.maxlen))//FLAGS.batch_size\n",
    "char2ind, ind2char = get_dicts(corpus=readfile(FLAGS.data_path))\n",
    "FLAGS.charlen = len(char2ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "N_HIDDEN = 512\n",
    "N_HIDDEN2 = 512\n",
    "LEARNING_RATE = 0.005\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building training model...\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "gru_2 (GRU)                      (None, 50, 512)       837120      gru_input_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_9 (TimeDistribut (None, 50, 512)       262656      gru_2[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_10 (TimeDistribu (None, 50, 512)       0           timedistributed_9[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_11 (TimeDistribu (None, 50, 32)        16416       timedistributed_10[0][0]         \n",
      "____________________________________________________________________________________________________\n",
      "timedistributed_12 (TimeDistribu (None, 50, 32)        0           timedistributed_11[0][0]         \n",
      "====================================================================================================\n",
      "Total params: 1,116,192\n",
      "Trainable params: 1,116,192\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Building training model...')\n",
    "model = Sequential()\n",
    "# The output of the LSTM layer are the hidden states of the LSTM for every time step. \n",
    "model.add(GRU(N_HIDDEN, return_sequences = True, input_shape=(maxlen, len(char2ind))))\n",
    "# Two things to notice here:\n",
    "# 1. The Dense Layer is equivalent to nn.Linear(hiddenStateSize, hiddenLayerSize) in Torch.\n",
    "#    In Keras, we often do not need to specify the input size of the layer because it gets inferred for us.\n",
    "# 2. TimeDistributed applies the linear transformation from the Dense layer to every time step\n",
    "#    of the output of the sequence produced by the LSTM.\n",
    "model.add(TimeDistributed(Dense(N_HIDDEN2)))\n",
    "model.add(TimeDistributed(Activation('relu'))) \n",
    "model.add(TimeDistributed(Dense(FLAGS.charlen)))  # Add another dense layer with the desired output size.\n",
    "model.add(TimeDistributed(Activation('softmax')))\n",
    "model.compile(loss='categorical_crossentropy', optimizer = RMSprop(lr=0.001))\n",
    "\n",
    "print(model.summary()) # Convenient function to see details about the network model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('Training model')\n",
    "model.fit_generator(generate_data(FLAGS), nb_epoch=1, samples_per_epoch=FLAGS.samples_per_epoch)\n",
    "model.save_weights(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# The only difference with the \"training model\" is that here the input sequence has \n",
    "# a length of one because we will predict character by character.\n",
    "print('Building Inference model...')\n",
    "inference_model = Sequential()\n",
    "# Two differences here.\n",
    "# 1. The inference model only takes one sample in the batch, and it always has sequence length 1.\n",
    "# 2. The inference model is stateful, meaning it inputs the output hidden state (\"its history state\")\n",
    "#    to the next batch input.\n",
    "inference_model.add(LSTM(N_HIDDEN, batch_input_shape=(1, 1, len(char2id)), stateful = True))\n",
    "# Since the above LSTM does not output sequences, we don't need TimeDistributed anymore.\n",
    "inference_model.add(Dense(N_HIDDEN2))\n",
    "inference_model.add(Activation('relu'))\n",
    "inference_model.add(Dense(FLAGS.charlen))\n",
    "inference_model.add(Activation('softmax'))\n",
    "\n",
    "# Copy the weights of the trained network. Both should have the same exact number of parameters (why?).\n",
    "inference_model.load_weights('model.h5')\n",
    "\n",
    "# Given the start Character 'S' (one-hot encoded), predict the next most likely character.\n",
    "startChar = np.zeros((1, 1, FLAGS.charlen))\n",
    "startChar[0, 0, char2id['S']] = 1\n",
    "nextCharProbabilities = inference_model.predict(startChar)\n",
    "\n",
    "# print the most probable character that goes next.\n",
    "print(id2char[nextCharProbabilities.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
